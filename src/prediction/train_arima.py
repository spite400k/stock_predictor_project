import os
from dotenv import load_dotenv
import pandas as pd
from datetime import timedelta
import matplotlib.pyplot as plt
from supabase import create_client, Client
from pmdarima import auto_arima

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Supabaseã®è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


def fetch_stock_data():
    """ trn_ranked_item_stock_pretreatment ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾— """
    try:
        response = supabase.table("trn_ranked_item_stock_pretreatment").select("*").execute()

        if "error" in response and response["error"]:
            print(f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {response['error']}")
            return None

        if response.data:
            df = pd.DataFrame(response.data)

            if 'update_time' not in df.columns:
                raise ValueError("âŒ 'update_time' ã‚«ãƒ©ãƒ ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“")

            df["update_time"] = pd.to_datetime(df["update_time"])
            df["stockout_time"] = pd.to_datetime(df["stockout_time"])
            df["restock_time"] = pd.to_datetime(df["restock_time"])

            df.sort_values(["site", "seller_site", "product_id", "update_time"], inplace=True)
            df.set_index("update_time", inplace=True)

            df["stockout_duration"] = (df["restock_time"] - df["stockout_time"]).dt.days.fillna(0)
            df["restock_duration"] = (df["stockout_time"] - df["restock_time"].shift(1)).dt.days.fillna(0)

            df["day_of_week"] = df.index.dayofweek
            df["month"] = df.index.month

            return df
        else:
            print("âš  ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def train_arima_and_forecast(df, site=None, seller_site=None, product_id=None):
    """ auto_arima ã‚’ä½¿ã£ã¦è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸å®šãƒ»äºˆæ¸¬ã—ã€ã‚°ãƒ©ãƒ•ä¿å­˜ """

    if df.index.nunique() < 3:
        print(f"âš  ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: site={site}, seller_site={seller_site}, product_id={product_id}")
        return None

    inferred_freq = pd.infer_freq(df.index)
    df = df.asfreq(inferred_freq if inferred_freq else "D")
    df.ffill(inplace=True)

    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("âŒ 'update_time' ãŒ DatetimeIndex ã«ãªã£ã¦ã„ã¾ã›ã‚“ï¼")

    df["stock_trend"] = df["stock_status"].astype(float).rolling(window=7, min_periods=1).mean()

    try:
        # ğŸ”¹ auto_arima ã«ã‚ˆã‚‹è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸å®š
        model = auto_arima(
            df["stock_trend"],
            seasonal=False,
            stepwise=True,
            suppress_warnings=True,
            error_action='ignore',
            trace=False
        )

        forecast_values = model.predict(n_periods=10)
        future_dates = [df.index[-1] + timedelta(days=i) for i in range(1, 11)]

        forecast_df = pd.DataFrame({
            "update_time": future_dates,
            "forecast": forecast_values,
            "site": site,
            "seller_site": seller_site,
            "product_id": product_id
        })

        # ğŸ“Š ã‚°ãƒ©ãƒ•ã®ä¿å­˜
        plt.figure(figsize=(10, 6))
        plt.plot(df.index, df["stock_trend"], label="å®Ÿæ¸¬å€¤ï¼ˆéå»ï¼‰")
        plt.plot(forecast_df["update_time"], forecast_df["forecast"], label="äºˆæ¸¬å€¤", linestyle="--", color="red")
        plt.title(f"åœ¨åº«äºˆæ¸¬: {site} / {seller_site} / {product_id}")
        plt.xlabel("æ—¥ä»˜")
        plt.ylabel("åœ¨åº«ãƒˆãƒ¬ãƒ³ãƒ‰")
        plt.legend()
        plt.grid(True)

        save_dir = "forecast_images2"
        os.makedirs(save_dir, exist_ok=True)
        filename = f"{save_dir}\{site}_{seller_site}_{product_id}.png".replace("/", "_")
        plt.savefig(filename)
        plt.close()
        print(f"âœ… ã‚°ãƒ©ãƒ•ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")

        return forecast_df

    except Exception as e:
        print(f"âŒ auto_arima ã®å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def save_forecast_to_supabase(forecast_df):
    """ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ Supabase ã«ä¿å­˜ """
    try:
        records = []
        for row in forecast_df.itertuples(index=False):
            records.append({
                "forecast_datetime": row.update_time.isoformat(),
                "forecast": row.forecast,
                "site": row.site,
                "seller_site": row.seller_site,
                "product_id": row.product_id
            })

        if records:
            response = supabase.table("stock_forecast_arima") \
                .upsert(records, on_conflict=["forecast_datetime", "site", "seller_site", "product_id"]) \
                .execute()

            if "error" in response and response["error"]:
                print(f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {response['error']}")
            else:
                print("âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ Supabase ã«ä¿å­˜ï¼ˆã¾ãŸã¯æ›´æ–°ï¼‰ã—ã¾ã—ãŸï¼")
        else:
            print("âš  ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    df = fetch_stock_data()
    if df is not None and not df.empty:
        grouped = df.groupby(["site", "seller_site", "product_id"])
        all_forecasts = []

        for (site, seller_site, product_id), group in grouped:
            forecast_df = train_arima_and_forecast(group, site, seller_site, product_id)
            if forecast_df is not None:
                all_forecasts.append(forecast_df)

        valid_forecasts = [df for df in all_forecasts if df is not None and not df.empty]
        if valid_forecasts:
            save_forecast_to_supabase(pd.concat(valid_forecasts))
        else:
            print("âš  æœ‰åŠ¹ãªäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
    else:
        print("âš  ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚")


if __name__ == "__main__":
    main()
